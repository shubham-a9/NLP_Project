{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubham-a9/NLP_Project/blob/main/Neural_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVgRIXKwmAtS"
      },
      "source": [
        "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model, Model\n",
        "import keras.backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5E3rvx6maoo",
        "outputId": "41acad7c-c03c-478d-b16b-35807fcd8a90"
      },
      "source": [
        "!pip install Faker\n",
        "\n",
        "from faker import Faker\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fake = Faker()\n",
        "Faker.seed(12345)\n",
        "random.seed(12345)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Faker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/dc/266528ca3f7e6c14016832b955adc4313b9c18529a5012e13c42b858c33f/Faker-8.1.1-py3-none-any.whl (1.2MB)\n",
            "\r\u001b[K     |▎                               | 10kB 13.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 19.4MB/s eta 0:00:01\r\u001b[K     |▉                               | 30kB 23.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 23.1MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51kB 25.2MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61kB 19.9MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 20.2MB/s eta 0:00:01\r\u001b[K     |██▎                             | 81kB 18.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 92kB 18.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 102kB 18.0MB/s eta 0:00:01\r\u001b[K     |███                             | 112kB 18.0MB/s eta 0:00:01\r\u001b[K     |███▍                            | 122kB 18.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 133kB 18.0MB/s eta 0:00:01\r\u001b[K     |████                            | 143kB 18.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 153kB 18.0MB/s eta 0:00:01\r\u001b[K     |████▌                           | 163kB 18.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 174kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 184kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 194kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 204kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 215kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 225kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 235kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 245kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 256kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 266kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 276kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 286kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 296kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 307kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 317kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 327kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 337kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 348kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 358kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 368kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 378kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 389kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 399kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 409kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 419kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 430kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 440kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 450kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 460kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 471kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 481kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 491kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 501kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 512kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 522kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 532kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 542kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 552kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 563kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 573kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 583kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 593kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 604kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 614kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 624kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 634kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 645kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 655kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 665kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 675kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 686kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 696kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 706kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 716kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 727kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 737kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 747kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 757kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 768kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 778kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 788kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 798kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 808kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 819kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 829kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 839kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 849kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 860kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 870kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 880kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 890kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 901kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 911kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 921kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 931kB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 942kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 952kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 962kB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 972kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 983kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 993kB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.0MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1MB 18.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.2MB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2MB 18.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.7/dist-packages (from Faker) (2.8.1)\n",
            "Requirement already satisfied: text-unidecode==1.3 in /usr/local/lib/python3.7/dist-packages (from Faker) (1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.4->Faker) (1.15.0)\n",
            "Installing collected packages: Faker\n",
            "Successfully installed Faker-8.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rgKWgxUvnn9"
      },
      "source": [
        "# Define format of the data we would like to generate\n",
        "FORMATS = ['short',\n",
        "           'medium',\n",
        "           'long',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'full',\n",
        "           'd MMM YYY', \n",
        "           'd MMMM YYY',\n",
        "           'dd MMM YYY',\n",
        "           'd MMM, YYY',\n",
        "           'd MMMM, YYY',\n",
        "           'dd, MMM YYY',\n",
        "           'd MM YY',\n",
        "           'd MMMM YYY',\n",
        "           'MMMM d YYY',\n",
        "           'MMMM d, YYY',\n",
        "           'dd.MM.YY']\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7Em6s5JtY__"
      },
      "source": [
        "def load_dataset(m):\n",
        "    \"\"\"\n",
        "        Loads a dataset with m examples and vocabularies\n",
        "        :m: the number of examples to generate\n",
        "    \"\"\"\n",
        "    \n",
        "    human_vocab = set()\n",
        "    machine_vocab = set()\n",
        "    dataset = []\n",
        "    Tx = 30\n",
        "    \n",
        "\n",
        "    for i in tqdm(range(m)):\n",
        "        h, m, _ = load_date()\n",
        "        if h is not None:\n",
        "            dataset.append((h, m))\n",
        "            human_vocab.update(tuple(h))\n",
        "            machine_vocab.update(tuple(m))\n",
        "    \n",
        "    human = dict(zip(sorted(human_vocab) + ['<unk>', '<pad>'], \n",
        "                     list(range(len(human_vocab) + 2))))\n",
        "    inv_machine = dict(enumerate(sorted(machine_vocab)))\n",
        "    machine = {v:k for k,v in inv_machine.items()}\n",
        " \n",
        "    return dataset, human, machine, inv_machine\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stQu_k3xtjaY"
      },
      "source": [
        "def load_date():\n",
        "    \"\"\"\n",
        "        Loads some fake dates \n",
        "        :returns: tuple containing human readable string, machine readable string, and date object\n",
        "    \"\"\"\n",
        "    dt = fake.date_object()\n",
        "\n",
        "    try:\n",
        "        human_readable = format_date(dt, format=random.choice(FORMATS),  locale='en_US')\n",
        "        human_readable = human_readable.lower()\n",
        "        human_readable = human_readable.replace(',','')\n",
        "        machine_readable = dt.isoformat()\n",
        "        \n",
        "    except AttributeError as e:\n",
        "        return None, None, None\n",
        "\n",
        "    return human_readable, machine_readable, dt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-P6pQZrwT8i"
      },
      "source": [
        "def preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty):\n",
        "    \n",
        "    X, Y = zip(*dataset)\n",
        "    \n",
        "    X = np.array([string_to_int(i, Tx, human_vocab) for i in X])\n",
        "    Y = [string_to_int(t, Ty, machine_vocab) for t in Y]\n",
        "    \n",
        "    Xoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), X)))\n",
        "    Yoh = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), Y)))\n",
        "\n",
        "    return X, np.array(Y), Xoh, Yoh"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i80V7R92gdg"
      },
      "source": [
        "def string_to_int(string, length, vocab):\n",
        "    \"\"\"\n",
        "    Converts all strings in the vocabulary into a list of integers representing the positions of the\n",
        "    input string's characters in the \"vocab\"\n",
        "    \n",
        "    Arguments:\n",
        "    string -- input string, e.g. 'Wed 10 Jul 2007'\n",
        "    length -- the number of time steps you'd like, determines if the output will be padded or cut\n",
        "    vocab -- vocabulary, dictionary used to index every character of your \"string\"\n",
        "    \n",
        "    Returns:\n",
        "    rep -- list of integers (or '<unk>') (size = length) representing the position of the string's character in the vocabulary\n",
        "    \"\"\"\n",
        "    \n",
        "    #make lower to standardize\n",
        "    string = string.lower()\n",
        "    string = string.replace(',','')\n",
        "    \n",
        "    if len(string) > length:\n",
        "        string = string[:length]\n",
        "        \n",
        "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
        "    \n",
        "    if len(string) < length:\n",
        "        rep += [vocab['<pad>']] * (length - len(string))\n",
        "    \n",
        "    #print (rep)\n",
        "    return rep\n",
        "\n",
        "\n",
        "def int_to_string(ints, inv_vocab):\n",
        "    \"\"\"\n",
        "    Output a machine readable list of characters based on a list of indexes in the machine's vocabulary\n",
        "    \n",
        "    Arguments:\n",
        "    ints -- list of integers representing indexes in the machine's vocabulary\n",
        "    inv_vocab -- dictionary mapping machine readable indexes to machine readable characters \n",
        "    \n",
        "    Returns:\n",
        "    l -- list of characters corresponding to the indexes of ints thanks to the inv_vocab mapping\n",
        "    \"\"\"\n",
        "    \n",
        "    l = [inv_vocab[i] for i in ints]\n",
        "    return l"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzqZV4qE2nLf"
      },
      "source": [
        "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
        "\n",
        "def run_example(model, input_vocabulary, inv_output_vocabulary, text):\n",
        "    encoded = string_to_int(text, Tx, input_vocabulary)\n",
        "    prediction = model.predict(np.array([encoded]))\n",
        "    prediction = np.argmax(prediction[0], axis=-1)\n",
        "    return int_to_string(prediction, inv_output_vocabulary)\n",
        "\n",
        "def run_examples(model, input_vocabulary, inv_output_vocabulary, examples=EXAMPLES):\n",
        "    predicted = []\n",
        "    for example in examples:\n",
        "        predicted.append(''.join(run_example(model, input_vocabulary, inv_output_vocabulary, example)))\n",
        "        print('input:', example)\n",
        "        print('output:', predicted[-1])\n",
        "    return predicted"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc12wZ_f2wff"
      },
      "source": [
        "def softmax(x, axis=1):\n",
        "    \"\"\"Softmax activation function.\n",
        "    # Arguments\n",
        "        x : Tensor.\n",
        "        axis: Integer, axis along which the softmax normalization is applied.\n",
        "    # Returns\n",
        "        Tensor, output of softmax transformation.\n",
        "    # Raises\n",
        "        ValueError: In case `dim(x) == 1`.\n",
        "    \"\"\"\n",
        "    ndim = K.ndim(x)\n",
        "    if ndim == 2:\n",
        "        return K.softmax(x)\n",
        "    elif ndim > 2:\n",
        "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "        s = K.sum(e, axis=axis, keepdims=True)\n",
        "        return e / s\n",
        "    else:\n",
        "        raise ValueError('Cannot apply softmax to a tensor that is 1D')\n",
        "        \n",
        "\n",
        "def plot_attention_map(model, input_vocabulary, inv_output_vocabulary, text, n_s = 128, num = 6, Tx = 30, Ty = 10):\n",
        "    \"\"\"\n",
        "    Plot the attention map.\n",
        "  \n",
        "    \"\"\"\n",
        "    attention_map = np.zeros((10, 30))\n",
        "    Ty, Tx = attention_map.shape\n",
        "    \n",
        "    s0 = np.zeros((1, n_s))\n",
        "    c0 = np.zeros((1, n_s))\n",
        "    layer = model.layers[num]\n",
        "\n",
        "    encoded = np.array(string_to_int(text, Tx, input_vocabulary)).reshape((1, 30))\n",
        "    encoded = np.array(list(map(lambda x: to_categorical(x, num_classes=len(input_vocabulary)), encoded)))\n",
        "\n",
        "    f = K.function(model.inputs, [layer.get_output_at(t) for t in range(Ty)])\n",
        "    r = f([encoded, s0, c0])\n",
        "    \n",
        "    for t in range(Ty):\n",
        "        for t_prime in range(Tx):\n",
        "            attention_map[t][t_prime] = r[t][0,t_prime,0]\n",
        "\n",
        "    # Normalize attention map\n",
        "#     row_max = attention_map.max(axis=1)\n",
        "#     attention_map = attention_map / row_max[:, None]\n",
        "\n",
        "    prediction = model.predict([encoded, s0, c0])\n",
        "    \n",
        "    predicted_text = []\n",
        "    for i in range(len(prediction)):\n",
        "        predicted_text.append(int(np.argmax(prediction[i], axis=1)))\n",
        "        \n",
        "    predicted_text = list(predicted_text)\n",
        "    predicted_text = int_to_string(predicted_text, inv_output_vocabulary)\n",
        "    text_ = list(text)\n",
        "    \n",
        "    # get the lengths of the string\n",
        "    input_length = len(text)\n",
        "    output_length = Ty\n",
        "    \n",
        "    # Plot the attention_map\n",
        "    plt.clf()\n",
        "    f = plt.figure(figsize=(8, 8.5))\n",
        "    ax = f.add_subplot(1, 1, 1)\n",
        "\n",
        "    # add image\n",
        "    i = ax.imshow(attention_map, interpolation='nearest', cmap='Blues')\n",
        "\n",
        "    # add colorbar\n",
        "    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
        "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
        "    cbar.ax.set_xlabel('Alpha value (Probability output of the \"softmax\")', labelpad=2)\n",
        "\n",
        "    # add labels\n",
        "    ax.set_yticks(range(output_length))\n",
        "    ax.set_yticklabels(predicted_text[:output_length])\n",
        "\n",
        "    ax.set_xticks(range(input_length))\n",
        "    ax.set_xticklabels(text_[:input_length], rotation=45)\n",
        "\n",
        "    ax.set_xlabel('Input Sequence')\n",
        "    ax.set_ylabel('Output Sequence')\n",
        "\n",
        "    # add grid and legend\n",
        "    ax.grid()\n",
        "\n",
        "    #f.show()\n",
        "    \n",
        "    return attention_map"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOhFdG8Lp5Yr",
        "outputId": "0e342936-e42f-41a3-b3e1-ca2546832bb4"
      },
      "source": [
        "m = 10000\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)\n",
        "dataset[:10]\n",
        "human_vocab\n",
        "machine_vocab"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:00<00:00, 15053.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'-': 0,\n",
              " '0': 1,\n",
              " '1': 2,\n",
              " '2': 3,\n",
              " '3': 4,\n",
              " '4': 5,\n",
              " '5': 6,\n",
              " '6': 7,\n",
              " '7': 8,\n",
              " '8': 9,\n",
              " '9': 10}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZGWprQJs3xd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f3aabb-a1b8-4307-afc3-4958cb495898"
      },
      "source": [
        "Tx = 30\n",
        "Ty = 10\n",
        "len(human_vocab)\n",
        "\n",
        "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
        "\n",
        "print(\"X.shape:\", X.shape)\n",
        "print(\"Y.shape:\", Y.shape)\n",
        "print(\"Xoh.shape:\", Xoh.shape)\n",
        "print(\"Yoh.shape:\", Yoh.shape)\n",
        "\n",
        "index = 0\n",
        "print(\"Source date:\", dataset[index][0])\n",
        "print(\"Target date:\", dataset[index][1])\n",
        "print()\n",
        "print(\"Source after preprocessing (indices):\", X[index])\n",
        "print(\"Target after preprocessing (indices):\", Y[index])\n",
        "print()\n",
        "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
        "print(\"Target after preprocessing (one-hot):\", Yoh[index])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X.shape: (10000, 30)\n",
            "Y.shape: (10000, 10)\n",
            "Xoh.shape: (10000, 30, 37)\n",
            "Yoh.shape: (10000, 10, 11)\n",
            "Source date: 9 may 1998\n",
            "Target date: 1998-05-09\n",
            "\n",
            "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
            " 36 36 36 36 36 36]\n",
            "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
            "\n",
            "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TpeCgb03GBw"
      },
      "source": [
        "repeator = RepeatVector(Tx)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "densor1 = Dense(10, activation = \"tanh\")\n",
        "densor2 = Dense(1, activation = \"relu\")\n",
        "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
        "dotor = Dot(axes = 1)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC0Qmc3h3UME"
      },
      "source": [
        "def one_step_attention(a, s_prev):\n",
        "    s_prev = repeator(s_prev)\n",
        "    concat = concatenator([a, s_prev])\n",
        "    e = densor1(concat)\n",
        "    energies = densor2(e)\n",
        "    alphas = activator(energies)\n",
        "    context = dotor([alphas, a])\n",
        "    return context"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8tp_Goq3diL",
        "outputId": "379ff651-7035-4931-a9bf-0c4e1cb2060e"
      },
      "source": [
        "n_a = 32\n",
        "n_s = 64\n",
        "post_activation_LSTM_cell = LSTM(n_s, return_state = True)\n",
        "output_layer = Dense(len(machine_vocab), activation=softmax)\n",
        "\n",
        "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
        "    X = Input(shape=(Tx, human_vocab_size))\n",
        "    s0 = Input(shape=(n_s,), name='s0')\n",
        "    c0 = Input(shape=(n_s,), name='c0')\n",
        "    s = s0\n",
        "    c = c0\n",
        "    outputs = []\n",
        "    a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
        "    for t in range(Ty):\n",
        "        context = one_step_attention(a, s)\n",
        "        s, _, c = post_activation_LSTM_cell(inputs = context, initial_state= [s, c])\n",
        "        out = output_layer(s)\n",
        "        outputs.append(out)\n",
        "    model = Model(inputs = [X, s0, c0], outputs = outputs)\n",
        "    return model\n",
        "\n",
        "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 30, 37)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "s0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 30, 64)       17920       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector (RepeatVector)    (None, 30, 64)       0           s0[0][0]                         \n",
            "                                                                 lstm[0][0]                       \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[6][0]                       \n",
            "                                                                 lstm[7][0]                       \n",
            "                                                                 lstm[8][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 30, 128)      0           bidirectional[0][0]              \n",
            "                                                                 repeat_vector[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[8][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[9][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 30, 10)       1290        concatenate[0][0]                \n",
            "                                                                 concatenate[1][0]                \n",
            "                                                                 concatenate[2][0]                \n",
            "                                                                 concatenate[3][0]                \n",
            "                                                                 concatenate[4][0]                \n",
            "                                                                 concatenate[5][0]                \n",
            "                                                                 concatenate[6][0]                \n",
            "                                                                 concatenate[7][0]                \n",
            "                                                                 concatenate[8][0]                \n",
            "                                                                 concatenate[9][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 30, 1)        11          dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[7][0]                      \n",
            "                                                                 dense[8][0]                      \n",
            "                                                                 dense[9][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "attention_weights (Activation)  (None, 30, 1)        0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "                                                                 dense_1[2][0]                    \n",
            "                                                                 dense_1[3][0]                    \n",
            "                                                                 dense_1[4][0]                    \n",
            "                                                                 dense_1[5][0]                    \n",
            "                                                                 dense_1[6][0]                    \n",
            "                                                                 dense_1[7][0]                    \n",
            "                                                                 dense_1[8][0]                    \n",
            "                                                                 dense_1[9][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 64)        0           attention_weights[0][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[1][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[2][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[3][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[4][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[5][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[6][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[7][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[8][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[9][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "c0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 64), (None,  33024       dot[0][0]                        \n",
            "                                                                 s0[0][0]                         \n",
            "                                                                 c0[0][0]                         \n",
            "                                                                 dot[1][0]                        \n",
            "                                                                 lstm[0][0]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "                                                                 dot[2][0]                        \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[1][2]                       \n",
            "                                                                 dot[3][0]                        \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[2][2]                       \n",
            "                                                                 dot[4][0]                        \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[3][2]                       \n",
            "                                                                 dot[5][0]                        \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[4][2]                       \n",
            "                                                                 dot[6][0]                        \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[5][2]                       \n",
            "                                                                 dot[7][0]                        \n",
            "                                                                 lstm[6][0]                       \n",
            "                                                                 lstm[6][2]                       \n",
            "                                                                 dot[8][0]                        \n",
            "                                                                 lstm[7][0]                       \n",
            "                                                                 lstm[7][2]                       \n",
            "                                                                 dot[9][0]                        \n",
            "                                                                 lstm[8][0]                       \n",
            "                                                                 lstm[8][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 11)           715         lstm[0][0]                       \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[6][0]                       \n",
            "                                                                 lstm[7][0]                       \n",
            "                                                                 lstm[8][0]                       \n",
            "                                                                 lstm[9][0]                       \n",
            "==================================================================================================\n",
            "Total params: 52,960\n",
            "Trainable params: 52,960\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M73at4UGgEx5"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "opt = optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "### END CODE HERE ###"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA51UaiMIsCa"
      },
      "source": [
        "s0 = np.zeros((m, n_s))\n",
        "c0 = np.zeros((m, n_s))\n",
        "outputs = list(Yoh.swapaxes(0,1))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UABHDhby3k16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24a917f6-cb0b-4c87-815a-f98dff45184e"
      },
      "source": [
        "model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 25s 69ms/step - loss: 21.9383 - dense_2_loss: 2.2843 - dense_2_1_loss: 2.0210 - dense_2_2_loss: 2.3017 - dense_2_3_loss: 2.6242 - dense_2_4_loss: 1.6902 - dense_2_5_loss: 1.9205 - dense_2_6_loss: 2.6418 - dense_2_7_loss: 1.6181 - dense_2_8_loss: 2.1173 - dense_2_9_loss: 2.7191 - dense_2_accuracy: 0.0038 - dense_2_1_accuracy: 0.2529 - dense_2_2_accuracy: 0.0916 - dense_2_3_accuracy: 0.0347 - dense_2_4_accuracy: 0.9246 - dense_2_5_accuracy: 0.0102 - dense_2_6_accuracy: 0.0056 - dense_2_7_accuracy: 0.9539 - dense_2_8_accuracy: 0.0098 - dense_2_9_accuracy: 0.0170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f293fabe1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kS7KGSoQ3xZZ",
        "outputId": "a8421b8b-a856-40cb-8b48-ff8bc0718fc6"
      },
      "source": [
        "model.summary()  \n",
        "\n",
        "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 30, 37)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "s0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 30, 64)       17920       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector (RepeatVector)    (None, 30, 64)       0           s0[0][0]                         \n",
            "                                                                 lstm[0][0]                       \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[6][0]                       \n",
            "                                                                 lstm[7][0]                       \n",
            "                                                                 lstm[8][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 30, 128)      0           bidirectional[0][0]              \n",
            "                                                                 repeat_vector[0][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[8][0]              \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 repeat_vector[9][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 30, 10)       1290        concatenate[0][0]                \n",
            "                                                                 concatenate[1][0]                \n",
            "                                                                 concatenate[2][0]                \n",
            "                                                                 concatenate[3][0]                \n",
            "                                                                 concatenate[4][0]                \n",
            "                                                                 concatenate[5][0]                \n",
            "                                                                 concatenate[6][0]                \n",
            "                                                                 concatenate[7][0]                \n",
            "                                                                 concatenate[8][0]                \n",
            "                                                                 concatenate[9][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 30, 1)        11          dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[7][0]                      \n",
            "                                                                 dense[8][0]                      \n",
            "                                                                 dense[9][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "attention_weights (Activation)  (None, 30, 1)        0           dense_1[0][0]                    \n",
            "                                                                 dense_1[1][0]                    \n",
            "                                                                 dense_1[2][0]                    \n",
            "                                                                 dense_1[3][0]                    \n",
            "                                                                 dense_1[4][0]                    \n",
            "                                                                 dense_1[5][0]                    \n",
            "                                                                 dense_1[6][0]                    \n",
            "                                                                 dense_1[7][0]                    \n",
            "                                                                 dense_1[8][0]                    \n",
            "                                                                 dense_1[9][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 64)        0           attention_weights[0][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[1][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[2][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[3][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[4][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[5][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[6][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[7][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[8][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "                                                                 attention_weights[9][0]          \n",
            "                                                                 bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "c0 (InputLayer)                 [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 64), (None,  33024       dot[0][0]                        \n",
            "                                                                 s0[0][0]                         \n",
            "                                                                 c0[0][0]                         \n",
            "                                                                 dot[1][0]                        \n",
            "                                                                 lstm[0][0]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "                                                                 dot[2][0]                        \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[1][2]                       \n",
            "                                                                 dot[3][0]                        \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[2][2]                       \n",
            "                                                                 dot[4][0]                        \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[3][2]                       \n",
            "                                                                 dot[5][0]                        \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[4][2]                       \n",
            "                                                                 dot[6][0]                        \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[5][2]                       \n",
            "                                                                 dot[7][0]                        \n",
            "                                                                 lstm[6][0]                       \n",
            "                                                                 lstm[6][2]                       \n",
            "                                                                 dot[8][0]                        \n",
            "                                                                 lstm[7][0]                       \n",
            "                                                                 lstm[7][2]                       \n",
            "                                                                 dot[9][0]                        \n",
            "                                                                 lstm[8][0]                       \n",
            "                                                                 lstm[8][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 11)           715         lstm[0][0]                       \n",
            "                                                                 lstm[1][0]                       \n",
            "                                                                 lstm[2][0]                       \n",
            "                                                                 lstm[3][0]                       \n",
            "                                                                 lstm[4][0]                       \n",
            "                                                                 lstm[5][0]                       \n",
            "                                                                 lstm[6][0]                       \n",
            "                                                                 lstm[7][0]                       \n",
            "                                                                 lstm[8][0]                       \n",
            "                                                                 lstm[9][0]                       \n",
            "==================================================================================================\n",
            "Total params: 52,960\n",
            "Trainable params: 52,960\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x612 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}